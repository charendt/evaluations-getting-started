{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Base Model Endpoints using Azure AI Evaluation APIs\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial provides a step-by-step guide on how to evaluate prompts against variety of model endpoints deployed on Azure AI Platform or non Azure AI platforms. \n",
    "\n",
    "This guide uses Python Class as an application target which is passed to Evaluate API provided by PromptFlow SDK to evaluate results generated by LLM models against provided prompts. \n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- [azure-ai-evaluation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk)\n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend 30 minutes running this sample. \n",
    "\n",
    "## About this example\n",
    "\n",
    "This example demonstrates evaluating model endpoints responses against provided prompts using azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Application\n",
    "\n",
    "We will use Evaluate API provided by Prompt Flow SDK. It requires a target Application or python Function, which handles a call to LLMs and retrieve responses. \n",
    "\n",
    "In the notebook, we will use an Application Target `ModelEndpoints` to get answers from multiple model endpoints against provided question aka prompts. \n",
    "\n",
    "This application target requires list of model endpoints and their authentication keys. For simplicity, we have provided them in the `env_var` variable which is passed into init() function of `ModelEndpoints`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please provide Azure AI Project details so that traces and eval results are pushing in the project in Azure AI Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.getenv(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.getenv(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.getenv(\"AZURE_PROJECT_NAME\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Endpoints\n",
    "The following code demonstrates how to call various model endpoints, and is configured based on `env_var` set above. For any model in `env_var`, if you do not have that model deployed in your AI project, please comment it out. If you have a model that you would like to test that does not correspond with one of the types seen below, please include that type in the `__call__` function and create a helper function to call the model's endpoint via REST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import TypedDict, Self\n",
      "from promptflow.tracing import trace\n",
      "\n",
      "\n",
      "class ModelEndpoints:\n",
      "    def __init__(self: Self, model: dict) -> str:\n",
      "        self.model = model\n",
      "\n",
      "    class Response(TypedDict):\n",
      "        query: str\n",
      "        response: str\n",
      "\n",
      "    @trace\n",
      "    def __call__(self: Self, query: str) -> Response:\n",
      "        output = self.chat_completion(query)\n",
      "        return output\n",
      "\n",
      "    def chat_completion(self: Self, query: str) -> Response:\n",
      "        from azure.ai.inference import ChatCompletionsClient\n",
      "        from azure.ai.inference.models import SystemMessage, UserMessage\n",
      "        from azure.core.credentials import AzureKeyCredential\n",
      "        from dotenv import load_dotenv\n",
      "        import os\n",
      "\n",
      "        endpoint = os.getenv(\"AZURE_OPENAI_INFERENCE_ENDPOINT\")\n",
      "        key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
      "\n",
      "        print(f\"endpoint: {endpoint}\")\n",
      "        print(f\"model: {self.model} \\n\")\n",
      "\n",
      "        client = ChatCompletionsClient(\n",
      "            endpoint=endpoint, \n",
      "            credential=AzureKeyCredential(key),\n",
      "            model=self.model,\n",
      "            temperature=0.7,\n",
      "            max_tokens=1000,\n",
      "            top_p=0.95,\n",
      "        )\n",
      "\n",
      "        output = client.complete(\n",
      "            messages=[\n",
      "                SystemMessage(content=\"You are a helpful assistant.\"),\n",
      "                UserMessage(content=query)\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        response = output[\"choices\"][0][\"message\"][\"content\"]\n",
      "        return {\"query\": query, \"response\": response}\n"
     ]
    }
   ],
   "source": [
    "!pygmentize utils/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ§ª Test your model enpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint: https://ai-serv-eval060765329650.openai.azure.com/models\n",
      "model: Phi-4 \n",
      "\n",
      "Query: What is the capital of Switzerland?\n",
      "Response: The capital of Switzerland is Bern. While Switzerland does not have a national capital in the same way many other countries do, Bern serves as the seat of the federal authorities and is considered the de facto capital.\n"
     ]
    }
   ],
   "source": [
    "from utils.models import ModelEndpoints\n",
    "\n",
    "def test_model(target: ModelEndpoints) -> None:\n",
    "    query = \"What is the capital of Switzerland?\"\n",
    "    result = target(query)\n",
    "\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "\n",
    "model = \"Phi-4\"\n",
    "target = ModelEndpoints(model)\n",
    "\n",
    "test_model(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Following code reads Json file \"data.jsonl\" which contains inputs to the Application Target function. It provides question, context and ground truth on each line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           query  \\\n",
      "0                 What is the capital of France?   \n",
      "1             Which tent is the most waterproof?   \n",
      "2           Which camping table is the lightest?   \n",
      "3  How much does TrailWalker Hiking Shoes cost?    \n",
      "\n",
      "                                             context  \\\n",
      "0                   France is the country in Europe.   \n",
      "1  #TrailMaster X4 Tent, price $250,## BrandOutdo...   \n",
      "2  #BaseCamp Folding Table, price $60,## BrandCam...   \n",
      "3  #TrailWalker Hiking Shoes, price $110## BrandT...   \n",
      "\n",
      "                                        ground_truth  \n",
      "0                                              Paris  \n",
      "1  The TrailMaster X4 tent has a rainfly waterpro...  \n",
      "2  The BaseCamp Folding Table has a weight of 15 lbs  \n",
      "3    The TrailWalker Hiking Shoes are priced at $110  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"test-data.jsonl\", lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of the LLM Judge\n",
    "To use Relevance and Cohenrence Evaluator, we will Azure Open AI model details as a **Judge** that can be passed as model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "judge_model = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "o3_judge_model = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=\"gpt-4o\",\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "# model_config = {\n",
    "#     \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#     \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "#     \"azure_deployment\": \"gpt-4o\",\n",
    "#     \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "# }\n",
    "\n",
    "# o3_mini_model_config = {\n",
    "#     \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_O1_ENDPOINT\"),\n",
    "#     \"api_key\": os.getenv(\"AZURE_OPENAI_O1_API_KEY\"),\n",
    "#     \"azure_deployment\": \"o3-mini\",\n",
    "#     \"api_version\": os.getenv(\"AZURE_OPENAI_O1_API_VERSION\")\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the evaluation\n",
    "\n",
    "The Following code runs Evaluate API and uses Content Safety, Relevance and Coherence Evaluator to evaluate results from different models.\n",
    "\n",
    "The following are the few parameters required by Evaluate API. \n",
    "\n",
    "+   Data file (Prompts): It represents data file 'data.jsonl' in JSON format. Each line contains question, context and ground truth for evaluators.     \n",
    "\n",
    "+   Application Target: It is name of python class which can route the calls to specific model endpoints using model name in conditional logic.  \n",
    "\n",
    "+   Model Name: It is an identifier of model so that custom code in the App Target class can identify the model type and call respective LLM model using endpoint URL and auth key.  \n",
    "\n",
    "+   Evaluators: List of evaluators is provided, to evaluate given prompts (questions) as input and output (answers) from LLM models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o-mini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-24 18:14:55 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run evaluations_getting_started_20250224_181452_960985, log path: C:\\Users\\charendt\\.promptflow\\.runs\\evaluations_getting_started_20250224_181452_960985\\logs.txt\n",
      "[2025-02-24 18:15:07 +0100][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-24 18:15:07 +0100][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-24 18:15:07 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rygw_4gw_20250224_181507_140842, log path: C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rygw_4gw_20250224_181507_140842\\logs.txt\n",
      "[2025-02-24 18:15:07 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_6b_0zps9_20250224_181507_140842, log path: C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_6b_0zps9_20250224_181507_140842\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 18:14:55 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:14:55 +0100   21844 execution          WARNING  Starting run without column mapping may lead to unexpected results. Please consult the following documentation for more information: https://aka.ms/pf/column-mapping\n",
      "2025-02-24 18:14:55 +0100   21844 execution.bulk     INFO     Current system's available memory is 9813.68359375MB, memory consumption of current process is 214.48828125MB, estimated available worker count is 9813.68359375/214.48828125 = 45\n",
      "2025-02-24 18:14:55 +0100   21844 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 4, 'estimated_worker_count_based_on_memory_usage': 45}.\n",
      "2025-02-24 18:14:58 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(10068)-Line number(0) start execution.\n",
      "2025-02-24 18:14:58 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(11016)-Line number(1) start execution.\n",
      "2025-02-24 18:14:58 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(30104)-Line number(2) start execution.\n",
      "2025-02-24 18:14:58 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(564)-Line number(3) start execution.\n",
      "2025-02-24 18:15:00 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(10068)-Line number(0) completed.\n",
      "2025-02-24 18:15:01 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:15:01 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 3.02 seconds. Estimated time for incomplete lines: 9.06 seconds.\n",
      "2025-02-24 18:15:02 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(564)-Line number(3) completed.\n",
      "2025-02-24 18:15:03 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:15:03 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.52 seconds. Estimated time for incomplete lines: 5.04 seconds.\n",
      "2025-02-24 18:15:03 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(30104)-Line number(2) completed.\n",
      "2025-02-24 18:15:04 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:15:04 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.02 seconds. Estimated time for incomplete lines: 2.02 seconds.\n",
      "2025-02-24 18:15:05 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(11016)-Line number(1) completed.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.02 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     The thread monitoring the process [10068-SpawnProcess-4] will be terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     The thread monitoring the process [11016-SpawnProcess-6] will be terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     The thread monitoring the process [30104-SpawnProcess-7] will be terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     The thread monitoring the process [564-SpawnProcess-5] will be terminated.\n",
      "2025-02-24 18:15:06 +0100   10068 execution.bulk     INFO     The process [10068] has received a terminate signal.\n",
      "2025-02-24 18:15:06 +0100   30104 execution.bulk     INFO     The process [30104] has received a terminate signal.\n",
      "2025-02-24 18:15:06 +0100   11016 execution.bulk     INFO     The process [11016] has received a terminate signal.\n",
      "2025-02-24 18:15:06 +0100     564 execution.bulk     INFO     The process [564] has received a terminate signal.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Process 11016 terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Process 30104 terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Process 564 terminated.\n",
      "2025-02-24 18:15:06 +0100   21844 execution.bulk     INFO     Process 10068 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"evaluations_getting_started_20250224_181452_960985\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:14:52.959079+01:00\"\n",
      "Duration: \"0:00:14.065290\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\evaluations_getting_started_20250224_181452_960985\"\n",
      "\n",
      "2025-02-24 18:15:07 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 3.9 seconds. Estimated time for incomplete lines: 11.7 seconds.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.03 seconds. Estimated time for incomplete lines: 4.06 seconds.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.39 seconds. Estimated time for incomplete lines: 1.39 seconds.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.09 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_6b_0zps9_20250224_181507_140842\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:15:07.137458+01:00\"\n",
      "Duration: \"0:00:05.291725\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_6b_0zps9_20250224_181507_140842\"\n",
      "\n",
      "2025-02-24 18:15:12 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:15:12 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.33 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-24 18:15:07 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 3.97 seconds. Estimated time for incomplete lines: 11.91 seconds.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.13 seconds. Estimated time for incomplete lines: 4.26 seconds.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:15:11 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.53 seconds. Estimated time for incomplete lines: 1.53 seconds.\n",
      "2025-02-24 18:15:12 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:15:12 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.33 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rygw_4gw_20250224_181507_140842\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:15:07.137458+01:00\"\n",
      "Duration: \"0:00:06.316715\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rygw_4gw_20250224_181507_140842\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"relevance\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:05.291725\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\charendt\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_6b_0zps9_20250224_181507_140842\"\n",
      "    },\n",
      "    \"groundedness\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:06.316715\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\charendt\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rygw_4gw_20250224_181507_140842\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "Evaluating Phi-4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-24 18:15:30 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run evaluations_getting_started_20250224_181528_113849, log path: C:\\Users\\charendt\\.promptflow\\.runs\\evaluations_getting_started_20250224_181528_113849\\logs.txt\n",
      "[2025-02-24 18:16:03 +0100][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-24 18:16:03 +0100][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-02-24 18:16:03 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_jpxjjfdk_20250224_181603_056509, log path: C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_jpxjjfdk_20250224_181603_056509\\logs.txt\n",
      "[2025-02-24 18:16:03 +0100][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bmqktqm2_20250224_181603_056509, log path: C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bmqktqm2_20250224_181603_056509\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 18:15:30 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:15:30 +0100   21844 execution          WARNING  Starting run without column mapping may lead to unexpected results. Please consult the following documentation for more information: https://aka.ms/pf/column-mapping\n",
      "2025-02-24 18:15:30 +0100   21844 execution.bulk     INFO     Current system's available memory is 9919.0546875MB, memory consumption of current process is 232.80859375MB, estimated available worker count is 9919.0546875/232.80859375 = 42\n",
      "2025-02-24 18:15:30 +0100   21844 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 4, 'estimated_worker_count_based_on_memory_usage': 42}.\n",
      "2025-02-24 18:15:32 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-11)-Process id(17672)-Line number(0) start execution.\n",
      "2025-02-24 18:15:32 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-14)-Process id(37416)-Line number(2) start execution.\n",
      "2025-02-24 18:15:32 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-12)-Process id(35072)-Line number(1) start execution.\n",
      "2025-02-24 18:15:32 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-13)-Process id(1872)-Line number(3) start execution.\n",
      "2025-02-24 18:15:36 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-11)-Process id(17672)-Line number(0) completed.\n",
      "2025-02-24 18:15:37 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:15:37 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 5.04 seconds. Estimated time for incomplete lines: 15.12 seconds.\n",
      "2025-02-24 18:15:44 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-13)-Process id(1872)-Line number(3) completed.\n",
      "2025-02-24 18:15:44 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:15:44 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 6.06 seconds. Estimated time for incomplete lines: 12.12 seconds.\n",
      "2025-02-24 18:15:55 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-12)-Process id(35072)-Line number(1) completed.\n",
      "2025-02-24 18:15:55 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:15:55 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 7.74 seconds. Estimated time for incomplete lines: 7.74 seconds.\n",
      "2025-02-24 18:16:01 +0100   21844 execution.bulk     INFO     Process name(SpawnProcess-14)-Process id(37416)-Line number(2) completed.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 7.31 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     The thread monitoring the process [17672-SpawnProcess-11] will be terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     The thread monitoring the process [37416-SpawnProcess-14] will be terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     The thread monitoring the process [1872-SpawnProcess-13] will be terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     The thread monitoring the process [35072-SpawnProcess-12] will be terminated.\n",
      "2025-02-24 18:16:02 +0100   37416 execution.bulk     INFO     The process [37416] has received a terminate signal.\n",
      "2025-02-24 18:16:02 +0100   17672 execution.bulk     INFO     The process [17672] has received a terminate signal.\n",
      "2025-02-24 18:16:02 +0100    1872 execution.bulk     INFO     The process [1872] has received a terminate signal.\n",
      "2025-02-24 18:16:02 +0100   35072 execution.bulk     INFO     The process [35072] has received a terminate signal.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Process 37416 terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Process 35072 terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Process 1872 terminated.\n",
      "2025-02-24 18:16:02 +0100   21844 execution.bulk     INFO     Process 17672 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"evaluations_getting_started_20250224_181528_113849\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:15:28.111848+01:00\"\n",
      "Duration: \"0:00:34.653126\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\evaluations_getting_started_20250224_181528_113849\"\n",
      "\n",
      "2025-02-24 18:16:03 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:16:06 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:16:06 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 3.55 seconds. Estimated time for incomplete lines: 10.65 seconds.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.02 seconds. Estimated time for incomplete lines: 4.04 seconds.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.43 seconds. Estimated time for incomplete lines: 1.43 seconds.\n",
      "2025-02-24 18:16:08 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:16:08 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.27 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bmqktqm2_20250224_181603_056509\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:16:03.053507+01:00\"\n",
      "Duration: \"0:00:06.144158\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bmqktqm2_20250224_181603_056509\"\n",
      "\n",
      "2025-02-24 18:16:09 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:16:09 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.53 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-02-24 18:16:03 +0100   21844 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-02-24 18:16:06 +0100   21844 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-02-24 18:16:06 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 3.78 seconds. Estimated time for incomplete lines: 11.34 seconds.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 2.02 seconds. Estimated time for incomplete lines: 4.04 seconds.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-02-24 18:16:07 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.55 seconds. Estimated time for incomplete lines: 1.55 seconds.\n",
      "2025-02-24 18:16:09 +0100   21844 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-02-24 18:16:09 +0100   21844 execution.bulk     INFO     Average execution time for completed lines: 1.53 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_jpxjjfdk_20250224_181603_056509\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-02-24 18:16:03.053507+01:00\"\n",
      "Duration: \"0:00:07.164869\"\n",
      "Output path: \"C:\\Users\\charendt\\.promptflow\\.runs\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_jpxjjfdk_20250224_181603_056509\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"relevance\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:06.144158\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\charendt\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_bmqktqm2_20250224_181603_056509\"\n",
      "    },\n",
      "    \"groundedness\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:07.164869\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": \"C:\\\\Users\\\\charendt\\\\.promptflow\\\\.runs\\\\azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_jpxjjfdk_20250224_181603_056509\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from utils.models import ModelEndpoints\n",
    "from azure.ai.evaluation import evaluate, RelevanceEvaluator, GroundednessEvaluator\n",
    "\n",
    "## Resoning models are not yet supported as a judge\n",
    "# judge_model = o3_judge_model\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(judge_model)\n",
    "groundedness_evaluator = GroundednessEvaluator(judge_model)\n",
    "\n",
    "evaluators = {\n",
    "    \"relevance\": relevance_evaluator,\n",
    "    \"groundedness\": groundedness_evaluator,\n",
    "}\n",
    "\n",
    "models = [\n",
    "    # \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"Phi-4\"\n",
    "]\n",
    "\n",
    "file_name = \"test-data.jsonl\"\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + f'/{file_name}'\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Evaluating {model}...\")\n",
    "    randomNum = random.randint(1111, 9999)\n",
    "    evaluation_name = \"Eval-Run-\" + str(randomNum) + \"-\" + model.title()\n",
    "\n",
    "    results = evaluate(\n",
    "        evaluation_name=evaluation_name,\n",
    "        data=path,\n",
    "        target=ModelEndpoints(model),\n",
    "        evaluators=evaluators,\n",
    "        azure_ai_project=azure_ai_project,\n",
    "        evaluator_config={\n",
    "            \"default\": {\n",
    "                \"column_mapping\": {\n",
    "                    \"response\": \"${data.ground_truth}\",\n",
    "                    \"context\": \"${data.context}\",\n",
    "                    \"query\": \"${data.query}\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>The capital of France is Paris. It is the larg...</td>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>France is the country in Europe.</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is accurate and fully addresses t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The RESPONSE introduces information (Paris) th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which tent is the most waterproof?</td>\n",
       "      <td>When it comes to waterproof tents, several bra...</td>\n",
       "      <td>Which tent is the most waterproof?</td>\n",
       "      <td>#TrailMaster X4 Tent, price $250,## BrandOutdo...</td>\n",
       "      <td>The TrailMaster X4 tent has a rainfly waterpro...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response provides partial information by m...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE accurately conveys the informatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which camping table is the lightest?</td>\n",
       "      <td>When it comes to lightweight camping tables, t...</td>\n",
       "      <td>Which camping table is the lightest?</td>\n",
       "      <td>#BaseCamp Folding Table, price $60,## BrandCam...</td>\n",
       "      <td>The BaseCamp Folding Table has a weight of 15 lbs</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response partially addresses the query by ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully grounded and accurate in...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How much does TrailWalker Hiking Shoes cost?</td>\n",
       "      <td>The cost of TrailWalker hiking shoes can vary ...</td>\n",
       "      <td>How much does TrailWalker Hiking Shoes cost?</td>\n",
       "      <td>#TrailWalker Hiking Shoes, price $110## BrandT...</td>\n",
       "      <td>The TrailWalker Hiking Shoes are priced at $110</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is accurate but incomplete, as it...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   outputs.query  \\\n",
       "0                 What is the capital of France?   \n",
       "1             Which tent is the most waterproof?   \n",
       "2           Which camping table is the lightest?   \n",
       "3  How much does TrailWalker Hiking Shoes cost?    \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  The capital of France is Paris. It is the larg...   \n",
       "1  When it comes to waterproof tents, several bra...   \n",
       "2  When it comes to lightweight camping tables, t...   \n",
       "3  The cost of TrailWalker hiking shoes can vary ...   \n",
       "\n",
       "                                    inputs.query  \\\n",
       "0                 What is the capital of France?   \n",
       "1             Which tent is the most waterproof?   \n",
       "2           Which camping table is the lightest?   \n",
       "3  How much does TrailWalker Hiking Shoes cost?    \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0                   France is the country in Europe.   \n",
       "1  #TrailMaster X4 Tent, price $250,## BrandOutdo...   \n",
       "2  #BaseCamp Folding Table, price $60,## BrandCam...   \n",
       "3  #TrailWalker Hiking Shoes, price $110## BrandT...   \n",
       "\n",
       "                                 inputs.ground_truth  \\\n",
       "0                                              Paris   \n",
       "1  The TrailMaster X4 tent has a rainfly waterpro...   \n",
       "2  The BaseCamp Folding Table has a weight of 15 lbs   \n",
       "3    The TrailWalker Hiking Shoes are priced at $110   \n",
       "\n",
       "   outputs.relevance.relevance  outputs.relevance.gpt_relevance  \\\n",
       "0                            4                                4   \n",
       "1                            3                                3   \n",
       "2                            3                                3   \n",
       "3                            4                                4   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The response is accurate and fully addresses t...   \n",
       "1  The response provides partial information by m...   \n",
       "2  The response partially addresses the query by ...   \n",
       "3  The response fully addresses the query with ac...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  1                                      1   \n",
       "1                                  5                                      5   \n",
       "2                                  5                                      5   \n",
       "3                                  4                                      4   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  line_number  \n",
       "0  The RESPONSE introduces information (Paris) th...            0  \n",
       "1  The RESPONSE accurately conveys the informatio...            1  \n",
       "2  The RESPONSE is fully grounded and accurate in...            2  \n",
       "3  The RESPONSE is accurate but incomplete, as it...            3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results[\"rows\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, you can view the results in the Azure AI Foundry portal and compare the evaluation results:\n",
    "\n",
    "![alt](assets\\ai-foundry-evaluation-comparison.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
